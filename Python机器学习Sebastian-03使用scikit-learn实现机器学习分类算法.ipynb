{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本章中，我们将学到如下内容：\n",
    "+ 介绍常用分类算法的概念\n",
    "+ 使用scikit-learn机器学习库\n",
    "+ 选择机器学习算法时需要注意的问题  \n",
    "\n",
    "5  \n",
    "# 3.1 分类算法的选择\n",
    "再次借用一下“没有免费午餐”理论：没有任何一种分类器可以在所有可能的应用场景下都有良好的表现  \n",
    "总而言之，分类器的性能、计算能力和预测能力，在很大程度上都依赖于用于模型训练的相关数据。训练机器学习算法所涉及的五个主要步骤可以概述如下：  \n",
    "1. 特征的选择  \n",
    "2. 确定性能评价标准\n",
    "3. 选择分类器及其优化算法\n",
    "4. 对模型性能的评估\n",
    "5. 算法的调优\n",
    "5  \n",
    "\n",
    "# 3.2 初涉scikit-learn的使用\n",
    "## 使用sckit-learn训练感知器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tsklearn\tdatasets\tload_iris() feature_names\n",
    "python\tsklearn\tdatasets\tload_iris() target\n",
    "python\tsklearn\tdatasets\tload_iris() data\n",
    "'''\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了评估训练得到的模型在未知数据上的表现，我们进一步将数据集划分为训练数据集和测试数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tsklearn\tmodel_selection\ttrain_test_split()\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此，我们将使用scikit-learn的preprocessing模块中的standardscaler类对特征进行标准化处理  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler() \n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，我们要使用相同的缩放参数分别处理训练和测试数据集，以保证它们的值是彼此相当的  \n",
    "在对训练数据做了标准化处理后，我们现在可以训练感知器模型了。scikit-learn中的大多数算法本身就使用一对多方法来支持多类别分类，因此，我们可以将三种鸢尾花的数据同时输入到感知器中    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tsklearn\tLinear Models\tPerceptron() max_iter\n",
    "python\tsklearn\tLinear Models\tPerceptron() eta0\n",
    "'''\n",
    "from sklearn.linear_model import Perceptron\n",
    "ppn = Perceptron(max_iter = 40, eta0 = 0.1, random_state = 0)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此模型的参数eta0与我们自行实现的感知器中的学习速率eta等价，而参数max_iter定义了迭代的次数  \n",
    "与第2章中实现的感知器一样，使用scikit-learn完成模型的训练后，就可以在测试数据集上使用predict方法进行预测了 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tstr\tformat()\tformat() d\n",
    "'''\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: {:d}'.format((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "许多机器学习从业者通常使用准确率而不是误分类来评判一个模型，它们关系如下：  \n",
    "1 - 误分类率 = 准确率  \n",
    "可以通过metrics模块计算感知器在测试数据集上的分类准确率：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tsklearn\tClassification metrics\taccuracy_score()\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制刚刚训练过的模型的决策区域，我们做少许修改：使用小圆圈来高亮显示来自测试数据集的样本 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tnumpy\tArray manipulation routines\tunique()\n",
    "python\tmatplotlib\tcolors\tListedColormap()\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\tmin()\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\tmax()\n",
    "python\tnumpy\tArray creation routines\tmeshgrid()\n",
    "python\tmatplotlib\tPyplot function overview\tcontourf()\n",
    "python\tmatplotlib\tPyplot function overview\tscatter() alpha\n",
    "python\tmatplotlib\tcollections\tlabel\n",
    "'''\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_regions(X, y, classifier,\n",
    "                          test_idx = None, resolution = 0.02):\n",
    "    # 设置散点生成器和色图\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    \n",
    "    # 绘制决策边界\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                          np.arange(x2_min, x2_max, resolution)) \n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha = 0.4, cmap = cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    # 绘制样本分类\n",
    "    X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1],\n",
    "                   alpha = 0.8, color = cmap(idx),\n",
    "                   marker = markers[idx], label = cl)\n",
    "\n",
    "    # 高亮测试样本\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1], c = 'yellow',\n",
    "                   alpha = 0.5, linewidth = 1, marker = 'o',\n",
    "                   s = 55, label = 'test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "python\tnumpy\tArray manipulation routines\tvstack()\n",
    "python\tnumpy\tArray manipulation routines\thstack()\n",
    "python\tmatplotlib\tPyplot function overview\tlegend() loc\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "plot_decision_regions(X = X_combined_std,\n",
    "                     y = y_combined,\n",
    "                     classifier = ppn,\n",
    "                     test_idx = range(105,150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal length [standardized]')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果呈现的图像中我们可以看到，无法通过一个线性决策边界完美区分三类样本  \n",
    "对于无法完美线性可分的数据集，感知器算法将永远无法收敛，这也是在实践中一般不推荐使用感知器算法的原因 5\n",
    "# 3.3 逻辑斯蒂回归中的类别概率\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
