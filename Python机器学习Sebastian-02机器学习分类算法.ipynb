{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章将涵盖如下内容：\n",
    "+ 培养对机器学习算法的直观认识\n",
    "+ 使用pandas、numpy和matplotlib读取、处理和可视化数据\n",
    "+ 使用python实现线性分类算法 \n",
    "\n",
    "5\n",
    "# 2.1 人造神经元-早期机器学习概览\n",
    "为了理解大脑的工作原理以设计人工智能系统，沃伦·麦卡洛可与沃尔特·皮茨在1943年提出了第一个脑神经元的抽象模型，也称作麦卡洛可-皮茨神经元（MCP），神经元是大脑中互相连接的神经细胞，它可以处理和传递化学和电信号，如下图所示  \n",
    "![2-1](../syn_pic/py_machine_learning/2-1.png)\n",
    "麦卡洛可和皮茨将神经细胞描述为一个具备二进制输出的逻辑门  \n",
    "几年后，弗兰克·罗森布拉特基于MCP神经元模型提出了第一个感知器学习法则。在规则中提出了一个自学习算法，此算法可以自动通过优化得到权重系数，此系数与输入值的乘积决定了神经元是否被激活  \n",
    "我们把问题看作一个二值分类的任务，把两类分别记为1(正类别)和-1(负类别) 5  \n",
    "我们可以定义一个激励函数$\\varphi (z)$,它以特定的输入值x与相应的权值向量w的线性组合作为输入，其中，z也称作净输入($z=w_1x_1+\\dots+w_mx_m$):  \n",
    "$$w=\\left[\\begin{matrix}w_1 \\cr \\dots \\cr w_m\\end{matrix}\\right],x=\\left[\\begin{matrix}x_1 \\cr \\dots \\cr x_m\\end{matrix}\\right]$$  \n",
    "此时，对于一个特定样本$x^{(i)}$的激励，也就是$\\varphi(z)$的输出，如果其值大于预设的阈值$\\theta$，我们将其划分到1类，否则为-1类  \n",
    "在感知器算法中，激励函数$\\varphi (z)$是一个简单的分段函数  \n",
    "$$\\phi{(z)}=\\begin{cases}1&若z\\ge\\theta \\cr -1&其他\\end{cases}$$\n",
    "5  \n",
    "我们可以把阈值$\\theta$移到等式的左边，并增加一个初始项权重记为$w_0=-\\theta$且设$x_0=1$，这样我们就可以把z写成一个更加紧凑的形式：  \n",
    "$$z=w_0x_0+w_1x_1+\\dots+w_mx_m=w^Tx,\\theta(z)=\\begin{cases}1&若z\\ge\\theta \\cr -1&其他\\end{cases}$$\n",
    "注意：下面的小节中，使用向量点积来表示x和w乘积的和，而上标T则表示转置，它使得行向量和列向量之间能够互相转换  \n",
    "下图中，左图说明了感知器模型的激励函数如何将输入$z=w^Tx$转换到二值输出(-1或1),右图说明了感知器模型如何将两个可区分类别进行线性区分  \n",
    "![2-2](../syn_pic/py_machine_learning/2-2.png)\n",
    "5  \n",
    "MCP神经元和罗森布拉特阈值感知器的理念就是，通过模拟的方式还原大脑中单个神经元的工作方式：它是否被激活。最初的规则可总结为如下几步：  \n",
    "1. 将权重初始化为零或一个极小的随机数  \n",
    "2. 迭代所有训练样本$x^{(i)}$，执行如下操作：\n",
    "    1. 计算输出值$\\hat{y}$\n",
    "    2. 更新权重\n",
    "    \n",
    "5  \n",
    "这里的输出值是指通过前面定义的单位阶跃函数预测得出的类标，而每次对权重向量中每一权重w的更新方式为：  \n",
    "$$w_j: = w_j + \\Delta{w_j}$$\n",
    "对于用于更新权重$w_j$的值$\\Delta w_j$, 可通过感知器学习规则计算获得：\n",
    "$$\\Delta{w_j} = \\eta(y^{(i)}-\\hat{y}^{(i)})x_j^{(i)}$$\n",
    "其中，$\\eta$为学习速率（一个介于0.0到1.0之间的常数）,$y^{(i)}$为第i个样本的真实类标，$\\hat{y}^{(i)}$为预测得到的类标 5  \n",
    "需特别注意，权重向量中的所有权重值是同时更新的，这意味着在所有的权重$\\Delta{w_j}$更新前，我们无法重新计算$\\hat{y}^{(i)}$  \n",
    "具体地，对于一个二维数据集，可通过下式进行更新：  \n",
    "$$\\Delta{w_0} = \\eta(y^{(i)} - output^{(i)})$$\n",
    "$$\\Delta{w_1} = \\eta(y^{(i)} - output^{(i)})x_1^{(i)}$$\n",
    "$$\\Delta{w_2} = \\eta(y^{(i)} - output^{(i)})x_2^{(i)}$$\n",
    "5  \n",
    "对于如下式所示的两种场景，若感知器对类标的预测正确，权重可不做更新：  \n",
    "$$\\Delta{w_j} = \\eta(-1^{(i)} - (-1^{(i)}))x_j^{(i)} = 0$$\n",
    "$$\\Delta{w_j} = \\eta(1^{(i)} - 1^{(i)})x_j^{(i)} = 0$$\n",
    "但是，在类标预测错误的情况下，权重的值会分别趋向于正类别或者负类别的方向：  \n",
    "$$\\Delta{w_j} = \\eta(1^{(i)} - (-1^{(i)}))x_j^{(i)} = \\eta(2)x_j^{(i)}$$\n",
    "$$\\Delta{w_j} = \\eta(-1^{(i)} - 1^{(i)})x_j^{(i)} = \\eta(-1)x_j^{(i)}$$\n",
    "5  \n",
    "为了对乘法因子x_j^{(i)}有个更直观的认识，我们看另一个简单的例子，其中  \n",
    "$$\\hat{y}^{(i)}=+1，y^{(i)}=-1，\\eta=1$$  \n",
    "假定$x_j^{(i)} = 0.5$, 且模型将此样本错误地分到了-1类别内  \n",
    "在此情况下，我们应将相应的权值增1，以保证下次遇到此样本时使得激励$x_j^{(i)} = w_j^{(i)}$能将其更多地判定为正类别，这也相当于增大其值大于单位阶跃函数阈值的概率，以使得此样本被判定为+1类  \n",
    "$$\\Delta{w_j} = (1^{(i)} - (-1^{(i)}))0.5^{(i)} = (2)0.5^{(i)}=1$$\n",
    "5  \n",
    "权重的更新与$x_j^{(i)}$的值成比例。例如，如果有另外一个样本$x_j^{(i)}=2$被错误分到了-1类别中，我们应更大幅度地移动决策边界，以保证下次遇到此样本时能正确分类  \n",
    "$$\\Delta{w_j} = (1^{(i)} - (-1^{(i)}))2^{(i)} = (2)2^{(i)}=4$$\n",
    "需要注意的是：感知器收敛的前提是两个类别必须是线性可分的，且学习速率足够小  \n",
    "如果两个类别无法通过一个线性决策边界进行划分，可以为模型在训练数据集上的学习迭代次数设置一个最大值，或者设置一个允许错误分类样本数量的阈值——否则，感知器训练算法将永远不停地更新权值  \n",
    "![2-3](../syn_pic/py_machine_learning/2-3.png)\n",
    "5  \n",
    "![2-4](../syn_pic/py_machine_learning/2-4.png)\n",
    "上图说明了感知器如何接受样本x的输入，并将其与权值w进行加权以计算净输入。进而净输入被传递到激励函数（在此为单位阶跃函数），然后生成值为+1或者-1的二值输出，并以其作为样本的预测类标  \n",
    "在学习阶段，此输出用来计算预测的误差并更新权重 5 \n",
    "# 2.2 使用Python实现感知器学习算法\n",
    "在上一节中，我们已经学习了罗森布拉特感知器的工作方式，现在使用Python来实现它，并且将其应用于第1章中提到的鸢尾花数据集中  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "python\tnumpy\tArray creation routines\tnp.zeros()\n",
    "python\tnumpy\tArray objects\tndarray.shape\n",
    "python\tpython\tBuilt-in Functions\trange()\n",
    "python\tpython\tBuilt-in Functions\tzip()\n",
    "python\tSequence Types — list, tuple, range\ts.append()\ts.append()\n",
    "python\tnumpy\tLinear algebra (numpy.linalg)\tnp.dot()\n",
    "python\tnumpy\tIndexing routines\tnp.where()\n",
    "'''\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    eta : float\n",
    "        学习速率 (介于 0.0 和 1.0)\n",
    "    n_iter : int\n",
    "        训练集的最大迭代次数\n",
    "\n",
    "    属性\n",
    "    ----------\n",
    "    w_ : 1d-array\n",
    "        权重\n",
    "    errors_ : list\n",
    "        被错误分类的样本数量列表\n",
    "    5 \n",
    "    \"\"\"\n",
    "    def __init__(self, eta = 0.01, n_iter = 10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"使用训练集训练模型\n",
    "        \n",
    "        参数\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            训练特征集，n_samples是样本量，n_features是特征数量\n",
    "    y : array-like, shape = [n_samples]\n",
    "        目标类标\n",
    "        \n",
    "    返回\n",
    "    ----------\n",
    "    self : object\n",
    "    5\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"计算净输入（净输入函数）\n",
    "        \"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"单位阶跃函数（激励函数），返回类标 5\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
