{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章将涵盖如下内容：\n",
    "+ 培养对机器学习算法的直观认识\n",
    "+ 使用pandas、numpy和matplotlib读取、处理和可视化数据\n",
    "+ 使用python实现线性分类算法 \n",
    "\n",
    "5\n",
    "# 2.1 人造神经元-早期机器学习概览\n",
    "为了理解大脑的工作原理以设计人工智能系统，沃伦·麦卡洛可与沃尔特·皮茨在1943年提出了第一个脑神经元的抽象模型，也称作麦卡洛可-皮茨神经元（MCP），神经元是大脑中互相连接的神经细胞，它可以处理和传递化学和电信号，如下图所示  \n",
    "![2-1](../syn_pic/py_machine_learning/2-1.png)\n",
    "麦卡洛可和皮茨将神经细胞描述为一个具备二进制输出的逻辑门  \n",
    "几年后，弗兰克·罗森布拉特基于MCP神经元模型提出了第一个感知器学习法则。在规则中提出了一个自学习算法，此算法可以自动通过优化得到权重系数，此系数与输入值的乘积决定了神经元是否被激活  \n",
    "我们把问题看作一个二值分类的任务，把两类分别记为1(正类别)和-1(负类别) 5  \n",
    "我们可以定义一个激励函数$\\varphi (z)$,它以特定的输入值x与相应的权值向量w的线性组合作为输入，其中，z也称作净输入($z=w_1x_1+\\dots+w_mx_m$):  \n",
    "$$w=\\left[\\begin{matrix}w_1 \\cr \\dots \\cr w_m\\end{matrix}\\right],x=\\left[\\begin{matrix}x_1 \\cr \\dots \\cr x_m\\end{matrix}\\right]$$  \n",
    "此时，对于一个特定样本$x^{(i)}$的激励，也就是$\\varphi(z)$的输出，如果其值大于预设的阈值$\\theta$，我们将其划分到1类，否则为-1类  \n",
    "在感知器算法中，激励函数$\\varphi (z)$是一个简单的分段函数  \n",
    "$$\\phi{(z)}=\\begin{cases}1&若z\\ge\\theta \\cr -1&其他\\end{cases}$$\n",
    "5  \n",
    "我们可以把阈值$\\theta$移到等式的左边，并增加一个初始项权重记为$w_0=-\\theta$且设$x_0=1$，这样我们就可以把z写成一个更加紧凑的形式：  \n",
    "$$z=w_0x_0+w_1x_1+\\dots+w_mx_m=w^Tx,\\theta(z)=\\begin{cases}1&若z\\ge\\theta \\cr -1&其他\\end{cases}$$\n",
    "注意：下面的小节中，使用向量点积来表示x和w乘积的和，而上标T则表示转置，它使得行向量和列向量之间能够互相转换  \n",
    "下图中，左图说明了感知器模型的激励函数如何将输入$z=w^Tx$转换到二值输出(-1或1),右图说明了感知器模型如何将两个可区分类别进行线性区分  \n",
    "![2-2](../syn_pic/py_machine_learning/2-2.png)\n",
    "5  \n",
    "MCP神经元和罗森布拉特阈值感知器的理念就是，通过模拟的方式还原大脑中单个神经元的工作方式：它是否被激活。最初的规则可总结为如下几步：  \n",
    "1. 将权重初始化为零或一个极小的随机数  \n",
    "2. 迭代所有训练样本$x^{(i)}$，执行如下操作：\n",
    "    1. 计算输出值$\\hat{y}$\n",
    "    2. 更新权重\n",
    "    \n",
    "5  \n",
    "这里的输出值是指通过前面定义的单位阶跃函数预测得出的类标，而每次对权重向量中每一权重w的更新方式为：  \n",
    "$$w_j: = w_j + \\Delta{w_j}$$\n",
    "对于用于更新权重$w_j$的值$\\Delta w_j$, 可通过感知器学习规则计算获得：\n",
    "$$\\Delta{w_j} = \\eta(y^{(i)}-\\hat{y}^{(i)})x_j^{(i)}$$\n",
    "其中，$\\eta$为学习速率（一个介于0.0到1.0之间的常数）,$y^{(i)}$为第i个样本的真实类标，$\\hat{y}^{(i)}$为预测得到的类标 5  \n",
    "需特别注意，权重向量中的所有权重值是同时更新的，这意味着在所有的权重$\\Delta{w_j}$更新前，我们无法重新计算$\\hat{y}^{(i)}$  \n",
    "具体地，对于一个二维数据集，可通过下式进行更新：  \n",
    "$$\\Delta{w_0} = \\eta(y^{(i)} - output^{(i)})$$\n",
    "$$\\Delta{w_1} = \\eta(y^{(i)} - output^{(i)})x_1^{(i)}$$\n",
    "$$\\Delta{w_2} = \\eta(y^{(i)} - output^{(i)})x_2^{(i)}$$\n",
    "5  \n",
    "对于如下式所示的两种场景，若感知器对类标的预测正确，权重可不做更新：  \n",
    "$$\\Delta{w_j} = \\eta(-1^{(i)} - (-1^{(i)}))x_j^{(i)} = 0$$\n",
    "$$\\Delta{w_j} = \\eta(1^{(i)} - 1^{(i)})x_j^{(i)} = 0$$\n",
    "但是，在类标预测错误的情况下，权重的值会分别趋向于正类别或者负类别的方向：  \n",
    "$$\\Delta{w_j} = \\eta(1^{(i)} - (-1^{(i)}))x_j^{(i)} = \\eta(2)x_j^{(i)}$$\n",
    "$$\\Delta{w_j} = \\eta(-1^{(i)} - 1^{(i)})x_j^{(i)} = \\eta(-1)x_j^{(i)}$$\n",
    "5  \n",
    "为了对乘法因子x_j^{(i)}有个更直观的认识，我们看另一个简单的例子，其中  \n",
    "$$\\hat{y}^{(i)}=+1，y^{(i)}=-1，\\eta=1$$  \n",
    "假定$x_j^{(i)} = 0.5$, 且模型将此样本错误地分到了-1类别内  \n",
    "在此情况下，我们应将相应的权值增1，以保证下次遇到此样本时使得激励$x_j^{(i)} = w_j^{(i)}$能将其更多地判定为正类别，这也相当于增大其值大于单位阶跃函数阈值的概率，以使得此样本被判定为+1类  \n",
    "$$\\Delta{w_j} = (1^{(i)} - (-1^{(i)}))0.5^{(i)} = (2)0.5^{(i)}=1$$\n",
    "5  \n",
    "权重的更新与$x_j^{(i)}$的值成比例。例如，如果有另外一个样本$x_j^{(i)}=2$被错误分到了-1类别中，我们应更大幅度地移动决策边界，以保证下次遇到此样本时能正确分类  \n",
    "$$\\Delta{w_j} = (1^{(i)} - (-1^{(i)}))2^{(i)} = (2)2^{(i)}=4$$\n",
    "需要注意的是：感知器收敛的前提是两个类别必须是线性可分的，且学习速率足够小  \n",
    "如果两个类别无法通过一个线性决策边界进行划分，可以为模型在训练数据集上的学习迭代次数设置一个最大值，或者设置一个允许错误分类样本数量的阈值——否则，感知器训练算法将永远不停地更新权值  \n",
    "![2-3](../syn_pic/py_machine_learning/2-3.png)\n",
    "5  \n",
    "![2-4](../syn_pic/py_machine_learning/2-4.png)\n",
    "上图说明了感知器如何接受样本x的输入，并将其与权值w进行加权以计算净输入。进而净输入被传递到激励函数（在此为单位阶跃函数），然后生成值为+1或者-1的二值输出，并以其作为样本的预测类标  \n",
    "在学习阶段，此输出用来计算预测的误差并更新权重 5 \n",
    "# 2.2 使用Python实现感知器学习算法\n",
    "在上一节中，我们已经学习了罗森布拉特感知器的工作方式，现在使用Python来实现它，并且将其应用于第1章中提到的鸢尾花数据集中  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "python\tnumpy\tArray creation routines\tnp.zeros()\n",
    "python\tnumpy\tArray objects\tndarray.shape\n",
    "python\tpython\tBuilt-in Functions\trange()\n",
    "python\tpython\tBuilt-in Functions\tzip()\n",
    "python\tSequence Types — list, tuple, range\ts.append()\ts.append()\n",
    "python\tnumpy\tLinear algebra (numpy.linalg)\tnp.dot()\n",
    "python\tnumpy\tIndexing routines\tnp.where()\n",
    "'''\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier\n",
    "    \n",
    "    参数\n",
    "    ----------\n",
    "    eta : float\n",
    "        学习速率 (介于 0.0 和 1.0)\n",
    "    n_iter : int\n",
    "        训练集的最大迭代次数\n",
    "\n",
    "    属性\n",
    "    ----------\n",
    "    w_ : 1d-array\n",
    "        权重\n",
    "    errors_ : list\n",
    "        被错误分类的样本数量列表\n",
    "    5 \n",
    "    \"\"\"\n",
    "    def __init__(self, eta = 0.01, n_iter = 10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"使用训练集训练模型\n",
    "        \n",
    "        参数\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            训练特征集，n_samples是样本量，n_features是特征数量\n",
    "    y : array-like, shape = [n_samples]\n",
    "        目标类标\n",
    "        \n",
    "    返回\n",
    "    ----------\n",
    "    self : object\n",
    "    5\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1]) \n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"计算净输入（净输入函数）\n",
    "        \"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"单位阶跃函数（激励函数），返回类标 5\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在感知器实现过程中，我们实例化一个Perceptron对象时，给出了一个学习速率eta和在训练数据集上进行迭代的次数n_iter  \n",
    "通过fit方法，我们将self.w_中的权值初始化为一个零向量$R^{m+1}$，其中m是数据集中维度(特征)的数量，我们在此基础上增加一个0权重列(也就是激励函数的阈值，通过与激励函数的等式被移到式子中)  \n",
    "与python的列表类似，numpy也使用方括号([])对一维数组进行索引。对二维数组来说，第1个索引值对应数组的行，第2个索引值对应数组的列  \n",
    "初始化权重后，fit方法循环迭代数据集中的所有样本，并根据前面章节讨论过的感知器学习规则来更新权重  \n",
    "我们使用predict方法来计算类标，这个方法在fit方法中被调用，用于计算权重更新时的类标，在完成模型训练后，predict方法也用于预测未知数据的类标 5  \n",
    "此外，在每次迭代的过程中，我们收集每轮迭代中错误分类样本的数量，并将其存放于列表self.errors_中，以便后续对感知器在训练中表现的好坏做出判定  \n",
    "另外在net_input方法中使用的np.dot方法用于计算项链的点积$w^Tx$  \n",
    "除了使用numpy的a.dot(b)或np.dot(a,b)计算两个数组a和b的点积之外，还可以通过类似sum(i\\*j for i,j in zip(a,b))这样的经典python for循环结构来计算  \n",
    "numpy的优势在于其算术运算的向量化。我们可充分利用现代处理器单指令流多数据流架构的支持快速完成运算，而不是循环地对每个元素逐一进行计算  5\n",
    "## 基于鸢尾花数据集训练感知器模型  \n",
    "为了测试前面实现的感知器算法，我们从鸢尾花数据集中挑选了setosa和versicolor两种花的信息作为测试数据（二分类），当然也可以通过one-vs.all技术扩展到多类别的分类器应用中  \n",
    "另外出于可视化方面的原因，我们只考虑数据集中sepal-length和petal-length这两个特征  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tconda\tconda install\t==\n",
    "python\tsklearn\tdatasets\tload_iris()\n",
    "python\tsklearn\tdatasets\tload_iris() as_frame\n",
    "python\tsklearn\tdatasets\tload_iris() frame\n",
    "python\tpandas\tdataframe\td.tail()\n",
    "'''\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "iris.frame.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**遇到问题-conda无法升级scikit-learn==0.23.1**  \n",
    "**背景**  \n",
    "\n",
    "由于load_iris() 需要scikit-learn版本在0.23以上\n",
    "所以我通过conda install升级scikit-learn\n",
    "结果提示兼容性问题：The environment is inconsistent, please check the package plan carefully 5  \n",
    "**计划**\n",
    "1. 搜集相关资料\n",
    "2. 分析相关资料\n",
    "3. 制订解决方案\n",
    "\n",
    "5  \n",
    "**方案**\n",
    "资料链接\n",
    "1. https://stackoverflow.com/questions/55527354/the-environment-is-inconsistent-please-check-the-package-plan-carefully \n",
    "建议：conda install anaconda\n",
    "2. https://www.cnpython.com/qa/124929\n",
    "建议：conda install anaconda\n",
    "3. https://blog.csdn.net/sinat_37267278/article/details/103305673\n",
    "同1\n",
    "4. https://blog.csdn.net/qq_34970603/article/details/106419573\n",
    "https://www.jianshu.com/p/19422477cc3c\n",
    "建议：conda install anaconda\n",
    "5. https://www.jianshu.com/p/19422477cc3c\n",
    "建议： conda install anaconda + conda update --all\n",
    "5  \n",
    "\n",
    "采用conda install anaconda  \n",
    "解决问题 5  \n",
    "python\tconda\tconda install\tERROR 5  \n",
    "——————  \n",
    "提取前100个类标，其中分别包含50个山鸢尾类标和50个变色鸢尾类标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5\n",
    "python\tpandas\tdataframe\td.iloc[]\n",
    "python\tpandas\tseries\ts.values\n",
    "python\tpandas\tdataframe\td.values\n",
    "python\tmatplotlib\tPyplot function overview\tplt.scatter()\n",
    "python\tmatplotlib\tPyplot function overview\tplt.scatter() marker\n",
    "python\tmatplotlib\tPyplot function overview\tplt.scatter() c\n",
    "python\tmatplotlib\tcollections\tlabel\n",
    "python\tmatplotlib\tPyplot function overview\txlabel()\n",
    "python\tmatplotlib\tPyplot function overview\tylabel()\n",
    "python\tmatplotlib\tPyplot function overview\tlegend() loc\n",
    "python\tmatplotlib\tPyplot function overview\tfigure() figsize\n",
    "python\tmatplotlib\tPyplot function overview\txlim()\n",
    "python\tmatplotlib\tPyplot function overview\tylim()\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = df.iloc[:100,4].values\n",
    "y = np.where(y == 0, -1, 1)\n",
    "X = df.iloc[:100, [0,2]].values\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.scatter(X[:50, 0], X[:50, 1],\n",
    "           c = 'red', marker = 'o', label = 'setosa')\n",
    "plt.scatter(X[50:, 0], X[50:, 1],\n",
    "           c = 'blue', marker = 'x', label = 'versicolor')\n",
    "plt.xlabel('sepal length(cm)')\n",
    "plt.ylabel('petal length(cm)')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.ylim(0,6)\n",
    "plt.xlim(4,7.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们可以利用抽取出的鸢尾花数据子集来训练感知器了  \n",
    "同时，我们还将绘制每次迭代的错误分类数量的折线图，以检验算法是否收敛并找到可以分开两种类型鸢尾花的决策边界  \n",
    "**遇到问题-算法不收敛**  \n",
    "+ 方案1：剔除异常点\n",
    "+ 方案2：检查并调整算法\n",
    "\n",
    "由于该代码来源书籍，只有数据集与书本不一致，故采用方案1  \n",
    "5  \n",
    "**发现原因**  \n",
    "特征选择代码错误, 原书的数据集和现有数据集特征存放位置不同  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python\tmatplotlib\tPyplot function overview\tplot()\n",
    "python\tmatplotlib\tlines\tmarker\n",
    "'''\n",
    "ppn = Perceptron(eta = 0.1, n_iter = 10)\n",
    "ppn.fit(X, y)\n",
    "plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker = 'o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.xlim(1,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上图所示，我们的分类器在第6次迭代后就已经收敛，并且具备对训练样本进行正确分类的能力。下面通过一个简单的函数来实现对二维数据集决策边界的可视化  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5\n",
    "python\tnumpy\tArray manipulation routines\tunique()\n",
    "python\tBuilt-in Functions\tlen()\tlen()\n",
    "python\tmatplotlib\tcolors\tListedColormap()\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\tmin()\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\tmax()\n",
    "python\tnumpy\tArray creation routines\tarange() step\n",
    "python\tnumpy\tArray creation routines\tmeshgrid()\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\travel()\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\tndarray.T\n",
    "python\tnumpy\tThe N-dimensional array (ndarray)\treshape()\n",
    "python\tmatplotlib\tPyplot function overview\tcontourf()\n",
    "python\tBuilt-in Functions\tenumerate()\tenumerate()\n",
    "'''\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution = 0.02):\n",
    "    # 设置散点生成器和色图\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    \n",
    "    # 绘制决策边界\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                          np.arange(x2_min, x2_max, resolution)) \n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha = 0.4, cmap = cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    # 绘制样本分类\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1],\n",
    "                   alpha = 0.8, c = cmap(idx),\n",
    "                   marker = markers[idx], label = cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "meshgrid详解 \n",
    "python\tnumpy\tArray creation routines\tlinspace() num\n",
    "\n",
    "nx, ny = (3, 2) # 可以另外测试 nx, ny = (4, 3)\n",
    "x = np.linspace(0, 1, nx)\n",
    "y = np.linspace(0, 1, ny)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "print(x)\n",
    "print('-'*6)\n",
    "print(y)\n",
    "print('-'*6)\n",
    "print(xv)\n",
    "print('-'*6)\n",
    "print(yv)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X, y, classifier = ppn)\n",
    "plt.xlabel('sepal length(cm)')\n",
    "plt.ylabel('petal length(cm)')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frank Rosenblatt从数学上证明了：如果两个类别可以通过线性超平面进行划分，则感知器算法一定会收敛 5  \n",
    "# 2.3 自适应线性神经元及其学习的收敛性 \n",
    "在Frank Rosenblatt提出感知器算法几年之后， Bernard Widrow和他的博士生Tedd Hoff提出了Adaline算法， 这可以看作对之前算法的改进  \n",
    "Adaline算法阐明了代价函数的核心概念，并且对其作了最小化优化，这是理解逻辑斯蒂回归、支持向量机和后续章节涉及的回归模型等基于回归的高级机器学习分类算法的基础  \n",
    "基于Adaline规则的权重更新是通过一个连续的线性激励函数来完成的，而不像Rosenblatt感知器那样使用单位阶跃函数，这是二者的主要区别  \n",
    "Adeline算法中作用于净输入的激励函数$\\varphi (z)$是简单的恒等函数， 即$\\varphi(w^Tx)=w^Tx$  \n",
    "线性激励函数在更新权重的同时，我们使用量化器对类标进行预测，量化器与前面提到的单位阶跃函数类似，如下图所示 5  \n",
    "![2-5](../syn_pic/py_machine_learning/2-5.png)\n",
    "与前文介绍的感知器算法的示意图进行比较，可以看出区别在于：这里使用线性激励函数的连续型输出值，而不是二类别分类类标来计算模型的误差以及更新权重 5  \n",
    "## 2.3.1 通过梯度下降最小化代价函数\n",
    "机器学习中监督学习算法的一个核心组成在于：在学习阶段定义一个待优化的目标函数。这个目标函数通常是需要我们做最小化处理的代价函数  \n",
    "在Adaline中，我们可以将代价函数J定义为通过模型得到的输出与实际类标之间的误差平方和（SSE）  \n",
    "$$J(w) = \\frac{1}{2}\\Sigma_i{(y^{(i)}-\\phi(z^{(i)}))^2}$$\n",
    "在此，系数1/2只是出于方便的考虑， 它使我们更容易导出梯度， 具体将在下一段落中介绍  \n",
    "与单位阶跃函数相比，这种连续型激励函数的主要优点在于：其代价函数是可导的 5  \n",
    "此代价函数的另一个优点在于：它是一个凸函数；这样，我们可以通过简单、高效的梯度下降优化算法来得到权重，且能保证在对鸢尾花数据集中样本进行分类时代价函数最小  \n",
    "我们将梯度下降的原理形象地描述为下山，直到获得一个局部或者全局最小值  \n",
    "在每次迭代中，根据给定地学习速率和梯度地斜率，能够确定每次移动地步幅，我们按照步幅沿着梯度方向前进一步  \n",
    "![2-6](../syn_pic/py_machine_learning/2-6.png)\n",
    "通过梯度下降，我们可以基于代价函数J(w)沿梯度$\\nabla J(w)$方向做一次权重更新： 5  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
